{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import IntegerType, TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('Cognitivo AI') \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to help data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dict(filename: str) -> dict:\n",
    "   with open(filename) as f:\n",
    "       return(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_column_type(df: DataFrame, column_name: str, column_type: str) -> DataFrame:\n",
    "    df = df.withColumn(\n",
    "        column_name, \n",
    "        df[column_name].cast(eval(f'{column_type.capitalize()}Type()'))\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data/input/users/load.csv'\n",
    "output_folder = 'data/output/'\n",
    "schema_file = 'config/types_mapping.json'\n",
    "schema_dict = json_to_dict(schema_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- create_date: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(input_file, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the dataset to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.coalesce(1).write.mode(\"overwrite\").parquet(f'{output_folder}1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict.update({'id': 'integer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in schema_dict.items():\n",
    "    df = change_column_type(df, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- create_date: timestamp (nullable = true)\n",
      " |-- update_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of using coalesce we could use repartition if we wanted to turn the grouped by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.coalesce(1).write.mode(\"overwrite\").parquet(f'{output_folder}2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only the last id of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='david.lynch@cognitivo.ai', email='David Lynch', phone='(11) 99999-9997', address='Mulholland Drive, Los Angeles, CA, US', age=72, create_date=datetime.datetime(2018, 3, 3, 18, 47, 1, 954752), update_date=datetime.datetime(2018, 3, 3, 18, 47, 1, 954752)),\n",
       " Row(id=1, name='david.lynch@cognitivo.ai', email='David Lynch', phone='(11) 99999-9998', address='Mulholland Drive, Los Angeles, CA, US', age=72, create_date=datetime.datetime(2018, 3, 3, 18, 47, 1, 954752), update_date=datetime.datetime(2018, 4, 14, 17, 9, 48, 558151)),\n",
       " Row(id=2, name='sherlock.holmes@cognitivo.ai', email='Sherlock Holmes', phone='(11) 94815-1623', address='221B Baker Street, London, UK', age=34, create_date=datetime.datetime(2018, 4, 21, 20, 21, 24, 364752), update_date=datetime.datetime(2018, 4, 21, 20, 21, 24, 364752)),\n",
       " Row(id=3, name='spongebob.squarepants@cognitivo.ai', email='Spongebob Squarepants', phone='(11) 91234-5678', address='124 Conch Street, Bikini Bottom, Pacific Ocean', age=13, create_date=datetime.datetime(2018, 5, 19, 4, 7, 6, 854752), update_date=datetime.datetime(2018, 5, 19, 4, 7, 6, 854752)),\n",
       " Row(id=1, name='david.lynch@cognitivo.ai', email='David Lynch', phone='(11) 99999-9999', address='Mulholland Drive, Los Angeles, CA, US', age=72, create_date=datetime.datetime(2018, 3, 3, 18, 47, 1, 954752), update_date=datetime.datetime(2018, 5, 23, 10, 13, 59, 594752))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, name: string, email: string, phone: string, address: string, age: int, create_date: timestamp, update_date: timestamp]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.sql(sqlQuery = '''\n",
    "    SELECT \n",
    "        *\n",
    "    FROM (\n",
    "        SELECT \n",
    "            *,\n",
    "            dense_rank() OVER (PARTITION BY id ORDER BY update_date DESC) AS rank\n",
    "        FROM users\n",
    "    ) a WHERE rank = 1\n",
    "''');\n",
    "df.drop('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='david.lynch@cognitivo.ai', email='David Lynch', phone='(11) 99999-9999', address='Mulholland Drive, Los Angeles, CA, US', age=72, create_date=datetime.datetime(2018, 3, 3, 18, 47, 1, 954752), update_date=datetime.datetime(2018, 5, 23, 10, 13, 59, 594752), rank=1),\n",
       " Row(id=3, name='spongebob.squarepants@cognitivo.ai', email='Spongebob Squarepants', phone='(11) 98765-4321', address='122 Conch Street, Bikini Bottom, Pacific Ocean', age=13, create_date=datetime.datetime(2018, 5, 19, 4, 7, 6, 854752), update_date=datetime.datetime(2018, 5, 19, 5, 8, 7, 964752), rank=1),\n",
       " Row(id=2, name='sherlock.holmes@cognitivo.ai', email='Sherlock Holmes', phone='(11) 94815-1623', address='221B Baker Street, London, UK', age=34, create_date=datetime.datetime(2018, 4, 21, 20, 21, 24, 364752), update_date=datetime.datetime(2018, 4, 21, 20, 21, 24, 364752), rank=1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.coalesce(1).write.mode(\"overwrite\").parquet(f'{output_folder}3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
